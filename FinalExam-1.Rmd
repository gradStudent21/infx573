---
title: "INFX 573 Final Exam"
author: "Pierre Augustamar"
date: "Due: Tueday, November 29, 2016"
output: pdf_document
header-includes:
- \newcommand{\benum}{\begin{enumerate}}
- \newcommand{\eenum}{\end{enumerate}}
- \newcommand{\bitem}{\begin{itemize}}
- \newcommand{\eitem}{\end{itemize}}
---               
                      
                      
##### Setup: #####                     
 
```{r Setup, message=FALSE, warning=FALSE}
#load  required libraries
library(tidyverse)
library(AER)
library(pROC)
library(randomForest)
library(bestglm)
library(ggfortify)
library(ISLR)
library(MASS)
library(rpart)
library(DAAG)
library(data.table)
```


##### Problem 1: #####                                                                   

In this problem we will use data about infidelitys, known as the Fair's Affairs dataset. The `Affairs` 
dataset is available as part of the AER package in R. This data comes from a survey conducted by 
Psychology Today in 1969, see Greene (2003) and Fair (1978) for more information.


The dataset contains various self-reported characteristics of 601 participants, including how often 
the respondent engaged in extramarital sexual intercourse during the past year, as well as their 
gender, age, year married, whether they had children, their religiousness (on a 5-point scale, from 
1=anti to 5=very), education, occupation (Hillinghead 7-point classification with reverse numbering), 
and a numeric self-rating of their marriage (from 1=very unhappy to 5=very happy).

Explore the data
```{r}
data("Affairs") # Get the Fair's affairs dataset
head(Affairs) # View the first 5 records from this data set
```

Check Data scruture and data types
```{r}
str(Affairs) # Show object's data type
summary(Affairs) # Generate a summary of the dataset
```


```{r}
# Using the data frame locally
affairs = as_data_frame(Affairs)
```


\begin{table}[ht]
\centering
\begin{tabular}{|l|l|}
\hline
{\bf Variable} & {\bf Description} \\ \hline \hline
affairs & How often engaged in extramarital \\
        & sexual intercourse during the past year? \\ \hline
gender  & factor indicating gender. \\ \hline
age     & numeric variable coding age in years:  \\ 
        & 17.5 = under 20, 22 = 20-24, 27 = 25-29, \\ 
        &  32 = 30-34, 37 = 35-39, 42 = 40-44, \\ 
        &  47 = 45-49, 52 = 50-54, 57 = 55 or over.\\ \hline
yearsmarried & numeric variable coding number of years married: \\ 
        & 0.125 = 3 months or less, 0.417 = 4-6 months, 0.75 = 6 months-1 year, \\
        & 1.5 = 1-2 years, 4 = 3-5 years, 7 = 6-8 years, \\
        & 10 = 9-11 years, 15 = 12 or more years. \\ \hline
children & factor. Are there children in the marriage? \\ \hline
religiousness & numeric variable coding religiousness: \\ 
              & 1 = anti, 2 = not at all, 3 = slightly, 4 = somewhat, 5 = very. \\ \hline
education & numeric variable coding level of education: \\ 
         & 9 = grade school, 12 = high school graduate, 14 = some college, \\ 
         & 16 = college graduate, 17 = some graduate work, \\ 
         & 18 = master's degree, 20 = Ph.D., M.D., or other advanced degree. \\ \hline
occupation & numeric variable coding occupation according to Hollingshead classification (reverse numbering). \\ \hline
rating     & numeric variable coding self rating of marriage: \\ 
           & 1 = very unhappy, 2 = somewhat unhappy, 3 = average, \\ 
           & 4 = happier than average, 5 = very happy. \\ 


\hline
\end{tabular}
\caption{Description of variables in the Fair's Extramarital Affairs Data}
\label{tab:data}
\end{table}
\vspace{.1in}

\newpage

\bitem
\item[(a)]	Describe the participants. Use descriptive, summarization, and exploratory techniques to 
describe the participants in the study. For example, what proportion of respondents are 
female? What is the average age of respondents? 

\textcolor{red}{Solution:} The data set contains 601 observations with 9 variables. Among those participants the summary analysis shows that 38.60 percent have a very happy marriage, 2.66 percent were very unhappy in their marriage, rougly 1 percent were either at or under 20 years old, 3.66 percent where either at or above 55 years old. Also, 28.46 percent of the participants did not have children, while 71.60 percent did have children. 11.65 percent considered themselves very religious while roughly 8% considered themselves atheist. In the education forum, 31.95 percent either had a Masters or higher education while 7.32% only had a high-school diploma. In the overall category,  75% of all the participants did not engage in any extramarital affairs, 2.16 percent very religious participants had an affair while 3.32 percent of atheist had an affair, 8.82 percent of participants with an advanced degree had an affair while 2.16 percent of people with a high school diploma had an affair. Meanwhile, roughly 0.50 percent of people under 20 had an affair, and similarly 0.50% of people 55 and older had an affair. In the gender specific, 52.41 percent considered themselves a female, 27.3 percent of male participants had an affair while 22.9 percent of women had an affair.  
 
```{r}
# Summarize participants' marriage rating and added a description label for the marriage rating
group_rating = affairs %>% 
                group_by(rating) %>% 
                summarise(frequency = n()) %>% 
                arrange(desc(frequency))

# Map marriage's rating with actual description 
marriage_rating_coding = group_rating %>% 
                  mutate(marriage_rating=ifelse(rating==5, "Very happy", 
                                         ifelse(rating==4, "happier than average", 
                                         ifelse(rating==3, "average", 
                                         ifelse(rating==2, "somewhat unhappy", 
                                         ifelse(rating==1, "very unhappy",NA)
                                         )))))

# Show frequency of marriage rating 
print(marriage_rating_coding)

# Generate a summary of the marriage rating
summary(marriage_rating_coding)

```


```{r}
# Calculate percentage of participants that have a very happy marriage
percentage.happy.marriage = (nrow(filter(affairs, rating==5))/nrow(affairs))*100
print(percentage.happy.marriage)

# Calculate percentage of particants that have a very unhappy marriage
percentage.unhappy.marriage = (nrow(filter(affairs, rating==1))/nrow(affairs))*100
print(percentage.unhappy.marriage)

```


```{r}
# Summarize participant's age and added a description label for the marriage coding
group_age  = affairs %>% 
             group_by(age) %>% 
             summarise(frequency=n()) %>% 
             arrange(desc(frequency))

marriage_age_coding  = group_age %>% 
                  mutate(age_level=ifelse(age <=20, "under 20", 
                                ifelse(age >20 & age <=24, "20-24", 
                                ifelse(age >24 & age<=29, "25-29", 
                                ifelse(age >29 & age<=34, "30-34", 
                                ifelse(age >34 & age <=39, "35-39", 
                                ifelse(age > 40 & age <=44, "40-44", 
                                ifelse(age >44 & age <=49, "45-49", 
                                ifelse(age > 49 & age <=54, "50-54", 
                                ifelse( age >=55, "55 or over", NA)
                                )))))))))


# Show frequency of marriage age 
print(marriage_age_coding)

# Generate a summary of the participants' age
summary(group_age)
```

```{r}

# summarize length of time participants have been married
 group_years_married = affairs %>% 
                        group_by(yearsmarried) %>% 
                        summarise(frequency=n()) %>% 
                        arrange(desc(frequency))

 years_married_coding = group_years_married %>% 
                        mutate(Year_married=ifelse(yearsmarried<=0.125, "3 months orless", 
                            ifelse(yearsmarried>0.125 & yearsmarried<=0.417, "4-6 months",
                            ifelse(yearsmarried>0.417 & yearsmarried <=0.75, "6 months-1 year",
                            ifelse(yearsmarried>0.75 & yearsmarried<=1.5, "1-2 years",
                            ifelse(yearsmarried>1.5 & yearsmarried<=4, "3-5 years", 
                            ifelse(yearsmarried>4 & yearsmarried <=7, "6-8 years", 
                            ifelse(yearsmarried>7 & yearsmarried<=10, "9-11 years",
                            ifelse(yearsmarried>10 & yearsmarried <=15, "12 or more years", NA)
                             ))))))))


# Show frequency of years married
print(years_married_coding) 
table(group_years_married) 

# Generate length of time partipants were married
summary(group_years_married)
```

```{r}
# Calculate percentage of participants that are under 20 years old
percentage.under.twenty = (nrow(filter(affairs, age <=20))/nrow(affairs))*100
print(percentage.under.twenty)

# Calculate percentage of particants that are 55 and above
percentage.above.fiftyfive = (nrow(filter(affairs, age >=55))/nrow(affairs))*100
print(percentage.above.fiftyfive)

```

```{r}
# Summarize participants with or without children
group.children = affairs %>% 
                  group_by(children) %>% 
                  summarise(frequency=n()) %>% 
                  arrange(desc(frequency))

# Explore frequency of with/out children
table(group.children)


```


```{r}
# Calculate percentage of parents that have children
percentage.have.children = (nrow(filter(affairs, children=="yes"))/nrow(affairs))*100
percentage.have.children

# Calculate percentage of parents that do not have children
percentage.no.children = 100 - percentage.have.children
print(percentage.no.children)

```


```{r}
# Summarize participants' religous background
group.religiousness = affairs %>% 
                      group_by(religiousness) %>% 
                      summarize(frequency=n()) %>% 
                      arrange(desc(frequency))

group.religiousness.coding = group.religiousness %>% 
                          mutate(religion_background=ifelse(religiousness==1, "anti", 
                              ifelse(religiousness==2, "not at all", 
                              ifelse(religiousness==3, "slightly", 
                              ifelse(religiousness==4, "somewhat", 
                              ifelse(religiousness==5, "very", NA)
                          )))))

# Show frequency of participant's religious background
print(group.religiousness.coding)

# Generate a summary of the participants' religious background
summary(group.religiousness)

```

```{r}
# Percentage of the participants that are very religious
percentage.very.religious = (nrow(filter(affairs, religiousness==5))/nrow(affairs))*100
print(percentage.very.religious)

# Percentage of the participants that are atheist
percentage.anti.religious = (nrow(filter(affairs, religiousness==1))/nrow(affairs))*100
print(percentage.anti.religious)

```


```{r}
# Summarize participants's education level 
group.education = affairs %>% 
                  group_by(education) %>% 
                  summarize(frequency=n()) %>% 
                  arrange(desc(frequency))

group.education.coding = group.education %>% 
                         mutate(education_level=(ifelse(education==9, "grade school", 
                            ifelse(education==12, "high school graduate", 
                            ifelse(education==14, "some college", 
                            ifelse(education==16, "college graduate", 
                            ifelse(education==17, "some graduate work", 
                            ifelse(education==18, "master's degree", 
                            ifelse(education==20, "Ph.D, M.D, or other advanced degree", NA)
                           ))))))))

# Show frequency of participants education level 
print(group.education.coding)

# Generate a summary of the participants' graduate work 
summary(group.education)

```


```{r}
# Percentage of participants that have a masters or above
percentage.higher.education = (nrow(filter(affairs, education %in% c(18,20)))/nrow(affairs))*100
print(percentage.higher.education)

# Percentage of participants that only have a high school diploma
percentage.highschool.diploma = (nrow(filter(affairs, education==12))/nrow(affairs))*100
print(percentage.highschool.diploma)

```


```{r}
# Summarize partitcipants' occupation
group.occupation = affairs %>% 
                   group_by(occupation) %>% 
                   summarize(frequency=n()) %>% 
                   arrange(desc(frequency))

group.occupation.coding = group.occupation %>% 
                     mutate(occupation_coding= (ifelse(occupation==1, "student",
                     ifelse(occupation==2, "farming, agriculture,unskilled worker", 
                     ifelse(occupation==3, "white-collar(sales,clerical,secretarial", 
                     ifelse(occupation==4, "teacher,counselor,social-worker,nurse,artist,writer",
                     ifelse(occupation==5, "managerial,administrative,business",
                     ifelse(occupation==6, "professional with advanced degree", NA
                      ))))))))

# Show frequency of participants based on occupation             
print(group.occupation.coding)

# Generate a summary of the participants' occupation 
summary(group.occupation)

```


```{r}
# Summarize husband's occupation
group.husband = filter(affairs, gender %in% c("male")) %>% 
                group_by(occupation) %>% 
                summarize(frequency=n()) %>% 
                arrange(desc(frequency))

group.husband.occupation = group.husband %>% 
                     mutate(occupation_coding= (ifelse(occupation==1, "student",
                     ifelse(occupation==2, "farming, agriculture,unskilled worker", 
                     ifelse(occupation==3, "white-collar(sales,clerical,secretarial", 
                     ifelse(occupation==4, "teacher,counselor,social-worker,nurse,artist,writer",
                     ifelse(occupation==5, "managerial,administrative,business",
                     ifelse(occupation==6, "professional with advanced degree", NA
                            ))))))))
   
# Show frequency of male's occupation
print(group.husband.occupation)

# Generate a summary of male's occupation 
summary(group.husband)
```


```{r}
# summarize female's occupation
group.wife = filter(affairs, gender %in% c("female")) %>% 
                group_by(occupation) %>% 
                summarize(frequency=n()) %>% 
                arrange(desc(frequency))

group.wife.occupation = group.wife %>% 
                    mutate(occupation_coding= (ifelse(occupation==1, "student",
                    ifelse(occupation==2, "farming, agriculture,unskilled worker", 
                    ifelse(occupation==3, "white-collar(sales,clerical,secretarial", 
                    ifelse(occupation==4, "teacher,counselor,social-worker,nurse,artist,writer",
                    ifelse(occupation==5, "managerial,administrative,business",
                    ifelse(occupation==6, "professional with advanced degree", NA
                           ))))))))
   
# Show frequency of female's occupation
print(group.wife.occupation)

# Generate a summary of female's occupation
summary(group.wife)
```


```{r}
# Percentage of participants that are female
female.participants =  filter(affairs, gender %in% c("female"))
percentage.female = (nrow(female.participants) / nrow(affairs))*100

# Show percentage of female's occupation
print(percentage.female)

```


```{r}

# Percentage of participants that didn't have an affair
participants.have.noaffair =  filter(affairs, affairs==0)
percentage.have.noaffair= (nrow(participants.have.noaffair) / nrow(affairs))*100

# Show percentage partcipants who did not have an affair
print(percentage.have.noaffair)

# Show Percentage of particpants who had an affair
percentage.have.anaffair = 100 - percentage.have.noaffair
print(percentage.have.anaffair)

```


```{r}

# Percentage of very religious participants who had an affair
participants.religious.have.affair =  filter(affairs, affairs >=1 & religiousness==5)
percentage.religious.have.affair= (nrow(participants.religious.have.affair) / nrow(affairs))*100

# Show percentage of very religious participants that had an affair
print(percentage.religious.have.affair)

# Percentage of atheist participants who had an affair
participants.atheist.have.affair =  filter(affairs, affairs >=1 & religiousness==1)
percentage.atheist.have.affair= (nrow(participants.atheist.have.affair) / nrow(affairs))*100
print(percentage.atheist.have.affair)
```

```{r}
# Percentage of participants who have a masters or an advanced degree and had an affair
participants.advancedDegree.have.affair =  filter(affairs, affairs >=1 & (education==18 | education ==20))
percentage.advancedDegree.have.affair= (nrow(participants.advancedDegree.have.affair) / nrow(affairs))*100

# Show percentage of very religious participants that had an affair
print(percentage.advancedDegree.have.affair)

# Percentage of participants with a high-school diploma and had an affair
participants.highschool.have.affair =  filter(affairs, affairs >=1 & education==12)
percentage.highschool.have.affair= (nrow(participants.highschool.have.affair) / nrow(affairs))*100
print(percentage.highschool.have.affair)
```


```{r}
# Percentage of participants under the age of 20 who had an affair
participants.underTwenty.have.affair =  filter(affairs, affairs >=1 & age <=20)
percentage.underTwenty.have.affair= (nrow(participants.underTwenty.have.affair) / nrow(affairs))*100

# Show percentage of pariticipants that are under 20 and had an affair
print(percentage.underTwenty.have.affair)

# Percentage of participants over the age of 55 who had an affair
participants.over55.have.affair =  filter(affairs, affairs >=1 & age >=55)
percentage.over55.have.affair= (nrow(participants.over55.have.affair) / nrow(affairs))*100
print(percentage.over55.have.affair)
```

```{r}
# Percentage of male participants who had an affair
male.participants.have.affair =  filter(affairs, gender=="male" & affairs >=1)
male.population = nrow(filter(affairs, gender=="male"))
percentage.male.have.affair= nrow(male.participants.have.affair) / (male.population)*100

# Show percentage of male who had an affair
print(percentage.male.have.affair)

# Percentage of female participants who had an affair
female.participants.have.affair =  filter(affairs, gender =="female" & affairs >=1)
female.population = nrow(filter(affairs, gender=="female"))
percentage.female.have.affair= nrow(female.participants.have.affair) / (female.population)*100
print(percentage.female.have.affair)
```

References:
    \bitem
     \item  http://www.doviak.net/courses/statistics/Fair-JPE-1978_data-descriptions.pdf
    \eitem 
 


\item[(b)]	Suppose we want to explore the characteristics of participants who engage in 
extramarital sexual intercourse (i.e. affairs). Instead of modeling the number of affairs, we 
will consider the binary outcome - had an affair versus didn't have an affair. Create a new 
variable to capture this response variable of interest. 

\textcolor{red}{Solution:} We added a new label, "had_an_affair" that will set to 0 if the participant did not have extramarital sexual intercourse. Otherwise, it will set any other values to yes which will signify that the user had an affair. 

```{r}
# Adding a new variable to hold binary (Yes or No) the particpants had an affair
Affairs = Affairs %>% 
          mutate(had_an_affair= ifelse(affairs==0, "NO", "YES"))


# Investigate whether the result is consistent and expected
head(Affairs)
tail(Affairs)

```

```{r}
# Calculate frequency of participants who either had an affair or did not
 participants.have.affair = Affairs %>% 
                        group_by(had_an_affair) %>% 
                        summarise(frequency=n()) %>% 
                        arrange(desc(frequency))
 
# Show a table representing participants had/not affair based on the binary
table(participants.have.affair)

```


\item[(c)]	Use an appropriate regression model to explore the relationship between having an affair 
and other personal characteristics. Comment on which covariates seem to be predictive 
of having an affair and which do not. 

\textcolor{red}{Solution:} In order to generate a glm with a binomial family we needed to have a column with a binary value of 0 and 1. Simirlarly, to what was done in the previous question, we added a new column that have 0 for affairs = 0 or no affair, and then 1 for affairs. The data generated can be explained as follows:

Partipants in general have 1.37 increase chance of having an affair. This will be our baseline. A male participant has 0.28 increase chance of having an affair. A participant's Age is 0.044 less of an indicator to cause someone to have an affair. The length of marriage is more than 0.094 chance to be the reason for someone to have an affair. Participants with children have 0.39 chance to have an affair. Participants religious beliefs or no beliefs is  0.32 less of an indicator to cause someone to have an affair. An educated participant has 0.02 more of a chance to have an affair. A participant with an occupation has 0.030 more of chance to have an affair. Participant's self rating of marriage has 0.47 less chance to be an indicator to cause someone to have an affair. 

The model shows that age, yearsmarried, religiousness, and rating are factors that are under a significant value of 0.05. Thus, these values can be used to either reject or fail to reject the null hypothesis on whether a participant eith had or did not have an affair. 
```{r}
set.seed(1233)
# Add a new label to hold affair has either 0 or 1
Affairs$hadaffair = ifelse(Affairs$affairs==0, 0, 1)
Affairs$hadaffair = as.integer(Affairs$hadaffair)

attach(Affairs) # Make these objects global

# Fit a logistic regression model for Fair's extreamarital affairs data
model = glm(hadaffair~gender+age+yearsmarried+children+religiousness+education+
              occupation+rating, data=Affairs, family = binomial)

summary(model) # display  results

```
 
\item[(d)]	Use an all subsets model selection procedure to obtain a "best" fit model. Is the model different 
from the full model you fit in part (c)? Which variables are included in the "best" fit model? 
You might found the bestglm() function available in the bestglm package helpful. 

\textcolor{red}{Solution:} The "best" fit model provides multiple options to judge the quality of this model. We could have used either BIC or AIC as both are maximum likelihood estimate driven. However, we decided to use the Akaike information criterion(AIC) because it is better suited for prediction. Ideally, the model with the smallest AIC is preferred. Based on the AIC's subset result, line 5 which has true for religiouness, yearsmarried, age, gender, and rating has the lowest AIC. Thus, it will be the best fit. 
```{r}
set.seed(1245)
# Generate the argument Xy needed for bestglm
Xy = cbind(gender,age,yearsmarried,children,religiousness,education,occupation,rating,hadaffair)
Xy = as.data.frame(Xy) # Set Xy as a dataframe 

```


```{r}
# Calculate best subset using AIC
bestAIC = bestglm(Xy, IC="AIC")
print(bestAIC)  
print(bestAIC$Subsets)
summary(bestAIC$BestModel)  #Overall best models
```

\bitem
     \item http://www2.uaem.mx/r-mirror/web/packages/bestglm/vignettes/bestglm.pdf
     \item http://stats.stackexchange.com/questions/577/is-there-any-reason-to-prefer-the-aic-or-bic-over-the-other
 \eitem



\item[(e)]	Interpret the model parameters using the model from part (d).
\textcolor{red}{Solution:} The "best" fit model is in this format bestglm(Xy, IC=<Criteria>". Xy represents the arguments containing the variables to be analyzed in the model with the last column containing the response. The result of this model can be expalined as follows: 
Partipants in general have 0.75 increase chance of having an affair. This will be our baseline. A male or a female participant has 0.06 increase chance of having an affair. A participant's Age is 0.007 less of an indicator to cause someone to have an affair.A participant's age has 0.0073 less chance to be an indicator to cause someone to have an affair. The length of marriage is more than 0.018 chance to be the reason for someone to have an affair.  A participant's religious beliefs or no beliefs are 0.05 less of and indicator to cause them to have an affair. Participant's self rating of marriage has 0.08 less chance to be an indicator to cause someone to have an affair. 

The model shows that age, yearsmarried, religiousness, and rating are factors that are under a significant value of 0.05. Thus, these values can be used to either reject or fail to reject the null hypothesis on whether a participant eith had or did not have an affair. 

Also, it's worth nothing that even though both the glm and the bestglm tend to come up with similar best fit model, the bestfit coefficients value seem to be a little stronger becuse it shows more than 3 stars for yearsmarried while glm only give the same variable only  a 2 star. 

\item[(f)]	Create an artificial test dataset where martial rating varies from 1 to 5 and all other 
variables are set to their means. Use this test dataset and the predict function to obtain 
predicted probabilities of having an affair for case in the test data. Interpret your results 
and use a visualization to support your interpretation. 

\textcolor{red}{Solution:} When generating the mean for all variables, we decided to skip gender and children. We did this because for this analysis getting the mean of being a male or female does not apply and also calculating the mean of either having children or not does not apply for this analysis. 

The residual graphs show multiple scattered plots to detect non-linearity, unequal error variances, and outlisers. The residual vs fitted suggest that there is a decreasing linear relationship when ratings are involved. 

We generated multiple graph analysis. Figrue 6 shows that the probability to have an affair decreases when the marriage rating goes from very unhappy to very happy. Thus, people who have a very happy marriage tends not to have an affair. 


```{r}
set.seed(23456)
# create a new model to be used for the prediction 
model2 = glm(hadaffair~as.factor(rating)+age+yearsmarried+religiousness+education+occupation, data=Affairs, family=binomial)
summary(model2)
confint(model2)

# Generate a new data that has affairs and the mean of all the other variables. 
newdata2 = with(Affairs, data.frame(age=mean(age),yearsmarried = mean(yearsmarried), religiousness = mean(religiousness), education = mean(education), occupation = mean(occupation), rating=factor(1:5)))

# Generate predicted probabilities 
newdata3 <- cbind(newdata2, predict(model2, newdata = newdata2, type="link", se=TRUE))
newdata3 <- within(newdata3, {
  PredictedProb <- plogis(fit)
  LL <- plogis(fit - (1.96 * se.fit)) # Add lower bound standard error
  UL <- plogis(fit + (1.96 * se.fit)) # Add upper bound standard error
})

head(newdata3) # View top 5 rows from the recordset 
```


```{r  Message=FALSE}
# Plotting diagnostics for glm
autoplot(model2, data = Affairs,
         colour = 'rating', label.size = 3, "Figure 6")

```


```{r}

ggplot(newdata3, aes(x = as.integer(rating), y = PredictedProb)) +
  geom_ribbon(aes(ymin = LL, ymax = UL), alpha = .2) +
  geom_line(aes(colour = as.integer(rating)), size=1)


```


References:
 \bitem
     \item  https://rstudio-pubs-static.s3.amazonaws.com/119859_a290e183ff2f46b2858db66c3bc9ed3a.html
     \item http://www.ats.ucla.edu/stat/r/dae/logit.htm
 \eitem 


\eitem

##### Problem 2: #####

In this problem we will revisit the state dataset. This data, available as part of the base R 
package, contains various data related to the 50 states of the United States of America.

Suppose you want to explore the relationship between a state's Murder rate and other 
characteristics of the state, for example population, illiteracy rate, and more. Follow the 
questions below to perform this analysis.

\textcolor{red}{Solution:} The dataset contains 50 observations with 8 variables. 

```{r}
# convert the matrix data as a data frame
stateInfo <- as.data.frame(state.x77) 

# Check the internal structure of the state data
str(stateInfo)
dim(stateInfo)
attach(stateInfo) # Make the objects global

```


\bitem
\item[(a)]	Examine the bivariate relationships present in the data. Briefly discuss notable results. 
You might find the scatterplotMatrix() function available in the car package helpful. 

\textcolor{red}{Solution:} The pairs function gives a general idea of all the possible relationships between all the variables. 

The scattter plot depicts multiple possible relationships. We decided to investigate the muder and life expectancy variables in relation to the other variables. We have identified the followings:
       Muder is negatively related to life expectancy
       Murder is negatively related to Frost
       Murder is  negatively related to illiteracy
       murder is negatively related to income  
       life expectancy is positively related to income
       life expectancy is negatively related to illeteracy
       life expectancy is positively related to High school graduate
       life expectancy is postiveely related to frost 
       
Also, we calculated the Pearson's r value to confirm the observations that we noticed from the scatterplot. We have found the followings for murder rate: 
   When comparing murder to illiteracy, the coefficient value = 0.70.This means that there is a strong positive linear correlation. 
   When comparing murder to life expectancy, the coefficient value = -0.78. This means that there is a strong negative correlation between murder rate and life expectancy rate. 
   when comparing murder to frost, the coefficient value = -0.538. This means that there is a moderate negative correlation between murder rate and frost rate. 
   When comparing murder to income, the coefficient value = -0.230. This means that there is a small negative correlation between murder rate and income rate. 
   
  Also, we have foudn the followings for life expectancy rate:
    when comparing life expectancy to income, the coefficient value = 0.340. This means there is a small positive correlatoin between life expectancy and income. 
    When comparing life expectancy to illiteracy, the coefficient value = - 0.59. This means there is a strong negative correlation between life expectancy and illiteracy. 
    when comparing life expectancy to High School, the coefficient value = 0.58. This means there is a strong postive correlation between life expectancy and high school graduation rate. 
    when comparing life expectancy to frost, the coefficient value = 0.26. This means there is a moderate positve correlation between life expectancy and frost. 

```{r}
# Generate a matrix of scattered plots for all of the variables. 
pairs(stateInfo)
 
# Calculate correlation coefficient for further analysis of the the model
cor(stateInfo) 

```

 
\item[(b)]	Fit a multiple linear regression model. How much variance in the murder rate across 
states do the predictor variables explain? 

\textcolor{red}{Solution:} The equation for the regression model will be as followed:
Y= 1.22e+02 + 1.88e-04*population + (-1.59e-04)*Income + (1.37e+00)*Illiteracy+ (-1.65e+00)*(`Life Exp`)+
   (3.23e-02)*(`HS Grad`)+(-1.29e-02)*Frost + (5.97e-06)*Area.
Y represent the murder rate for a specific state,thus, replacing the variables for a specific state then we can estimate whether murder rate will increase or decrease. Also, to estimate the variance in the murder rate, we analyze the residual standard error and the R-squared values. 

Based on the residual standard error, the actual murder rate increase or decrease in a specific state can deviate from the actual regression line by approximately 1.75 percentage rate. In other words, given that the mean possibiliy for the murder rate to increase for a state is around 1.22e+02. Note that the Residual Standard Error was calculated with 42 degrees of freedom.  

In this analysis, the R-squared we get is 0.8008. In other words, 80% of the variance found in the response variable (murder rate) can be explained by the predictor variables. This strong R-squared is saying that the predictors for this model are good predictors to estimated possible increase or decrese for a murder rate. 


```{r}
# Linear model to show relationship between murder rate and all the other variables
state.model = lm(stateInfo$Murder ~ ., data=stateInfo)

# Generate a summary of the linear model 
summary(state.model) 

```

References:
 \bitem
     \item  https://rstudio-pubs-static.s3.amazonaws.com/119859_a290e183ff2f46b2858db66c3bc9ed3a.html
 \eitem    
  
\item[(c)]	Evaluate the statistical assumptions in your regression analysis from part (b) by 
performing a basic analysis of model residuals and any unusual observations. Discuss 
any concerns you have about your model. 

\textcolor{red}{Solution:}We have analyzed the residual standard error in the previous quetion. Next, we are analyzing the residuals from part b. It shows five summary points. The symmetrical distribution of these points toward the mean is an indicator on how the model fit the data. Here we see that the distribution of the residuals is not too far off from the mean. 

Also, we plotted out the residuals for this model. The graphs showed somewhat a well-behaved residual vs fit.  We can note the followings:
  The residuals somewhat bounce randomly around the 0 line. This will suggest that there is a possible relationship and it is linear.  The residuals somewhat form an horizontal line around the 0 line. This suggests that the variances of the error terms are equal. Also, No one residuals are that far away to be considered as outliers. 


```{r}
# Get the residual model for this model 
plot(state.model)
```

 References: 

 \bitem
     \item http://www.statmethods.net/stats/regression.html
     \item https://onlinecourses.science.psu.edu/stat501/node/36
 \eitem 

\item[(d)]	Use a stepwise model selection procedure of your choice to obtain a "best" fit model. Is 
the model different from the full model you fit in part (b)? If yes, how so? 

\textcolor{red}{Solution:} For this analysis, we decided to use a stepAIC function from the MASS package. We used the "both" direction option. It gives a best fit model based on the aIC value. Ideally, the best model will be the one with the lowest AIC value. Based on this. It shows that our model will have the best fit when population, illiteracy, life expectancy, frost,and area are selected as predictors for estimating possible increase or decrease of murder rate. 

Yes, the model presented the stepAIC is different from the full model in part b. The reason for this is because in part be we considered the variables that were significant at 0.05. On the other hand, the stepAIC ran a more detailed analysis on the impact of adding or removing a variable from the model. 
```{r}
# Stepwise Regression

step <- stepAIC(state.model, direction="both")
step$anova # display results
```


\item[(e)]	Assess the model (from part (d)) generalizability. Perform a 10-fold cross validation to 
esti-mate model performance. Report the results. 

\textcolor{red}{Solution:} The chart shows 10 different colors nad shapes since we are performing a 10-fold cross-validation. The dotted lines represent the best fit per fold, and they appear to be parralel to each other.  
```{r}
# Calculate a Stepwise Regression
cv =  CVlm(data = stateInfo, m=10, form.lm = formula(Murder ~ Population + Income + 
                                  Illiteracy + `Life Exp` + `HS Grad` + Frost + Area))     
```


Reference: 

 \bitem
     \item http://math.furman.edu/~dcs/courses/math47/R/library/DAAG/html/CVlm.html
    
 \eitem 

\item[(f)]	Fit a regression tree using the same covariates in your "best" fit model from part (d). Use
cross validation to select the "best" tree. 

\textcolor{red}{Solution:} the decsion tree is divided into multiple decision makers. We notice that the life expectation above 72.31, population  greater than 5377, life expectancy above 70.67 and Area under 9147 were used to split the tree. 

```{r}

# Grow tree using best fit from part d
fit <- rpart(Murder~Population+Illiteracy+`Life Exp`+Frost+Area,
             method="class", data=stateInfo)

printcp(fit) # display the results 
plotcp(fit) # visualize cross-validation results 
summary(fit) # detailed summary of splits

# plot tree 
plot(fit, uniform=TRUE, 
  	main="Classification Tree for Kyphosis")
text(fit, use.n=TRUE, all=TRUE, cex=.8)

```


References:

 \bitem
     \item http://www.statmethods.net/advstats/cart.html
     \item http://web.stanford.edu/class/stats315b/minitech.pdf
 \eitem 


\item[(g)]	Compare the models from part (d) and (f) based on their performance. Which do you 
prefer? Be sure to justify your preference. 

\textcolor{red}{Solution:} the tree shows a better performance based on the split and the number of selections. It has a specific ways to identify the best fits. And it shows life expectancy as the best predictor to fit a model. 

\eitem

##### Problem 3: #####

The Wisconsin Breast Cancer dataset is available as a comma-delimited text file on the UCI 
Machine Learning Repository http://archive.ics.uci.edu/ml. Our goal in this problem will be to 
predict whether observations (i.e. tumors) are malignant or benign.

\bitem
\item[(a)]	Obtain the data, and load it into R by pulling it directly from the web. (Do not download it 
and import it from a CSV le.) Give a brief description of the data. 

\textcolor{red}{Solution:} The UCI repository contains multitple data sets, however, based on the documentations provided and the question asked, we concluded that the Wisconsin Diagnostic Breast Cancer (WDBC) contains data related to predicting whether the obvervations were diagnosed as either having a malignant or benign tumor. Thus, for this analysis we will be downloading the data captured for the Wisconsin Diagnostic Breast Cancer or WDBC. 

The data set containst 569 observations and 32 variables. 

```{r}
# Load data from UCI repository
mydat <- fread(
  'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
  ,header = FALSE
  )

# Explore data sctructure
str(mydat)  
head(mydat)
```


\item[(b)]	Tidy the data, ensuring that each variable is properly named and cast as the correct data 
type. Discuss any missing data. 

\textcolor{red}{Solution:}
The data set does not appear to have any missing values or "NA" values. Thus,there are no changes or cleanups needed. 

```{r}
# Look for any missing values
grepl("NA", mydat) 
```


We have renamed the variables based on the attribute information provided by the names documentation at: 
https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names. As stated, the columns are listed as: Id, diagnosis, and the following ten-real valued features:
 \bitem
  \item[a)] radius (mean of distances from center to points on the perimeter)
	\item[b)] texture (standard deviation of gray-scale values)
	\item[c)] perimeter
	\item[d)] area
	\item[e)] smoothness (local variation in radius lengths)
	\item[f)] compactness (perimeter^2 / area - 1.0)
	\item[g)] concavity (severity of concave portions of the contour)
	\item[h)] concave points (number of concave portions of the contour)
	\item[i)] symmetry 
	\item[j)] fractal dimension ("coastline approximation" - 1)
 \eitem 
 
The ten-real valued features are organized based on the mean, standard error, and worst. Thus, there will be 3 set of these ten-real valued, and for readability we will append them by "mean", "standardError", and "worst" respectively. 

```{r}

# Label the variables with descriptive value 
colnames(mydat) = c(
                    "id","diagnosis","radius_mean","texture_mean", 
                     "perimeter_mean", "area_mean","smoothness_mean",
                     "compactness_mean", "concavity_mean","concave_mean", 
                     "symmetry_mean", "fractal_mean",
                     "radius_standardError","texture_standardError", 
                     "perimeter_standardError","area_standardError", 
                     "smoothness_standardError","compactness_standardError", 
                     "concavity_standardError","concave_standardError",
                     "symmetry_standardError","fractal_standardError",
                     "radius_worst", "texture_worst","perimeter_worst", 
                     "area_worst","smoothness_worst","compactness_worst", 
                     "concavity_worst", "concave_worst", "symmetry_worst", 
                      "fractal_worst"
                   )

# Update the diagnosis label to it's full code name
mydat$diagnosis = ifelse(mydat$diagnosis=="B", "benign","malignant")

# Make diagnosis a factor variable 
mydat$diagnosis = as.factor(mydat$diagnosis)

```

```{r}
# Inspect updated variable name
str(mydat)

# Generate numerical summaries
summary(mydat)

```


\item[(c)]	Split the data into a training and validation set such that a random 70% of the 
observations are in the training set. 

\textcolor{red}{Solution:} the train data contains 398 records which is 70% of the whole data set. Similarly, the test data set contains 171 which is roughly 30% of the overall data set. Note that the original data set contains 569 records.  

```{r}
# Split into a training set and a test set
set.seed(3456) 
nrow(mydat)
num_train = round(.7*nrow(mydat))
trainInds = sample(1:nrow(mydat), num_train)
train = mydat[trainInds,]
test  = mydat[-trainInds,]

# Check total records for train and test data set 
nrow(train)
nrow(test)

```


\textcolor{red}{Solution:} the training data contains 244 patients that were diagnosed as benign and 154 patients that are diagnosed as having a malignant breast cancer. On the other hand, the test data shows 113 patients that were diagnosed as benign and 58 patients that were diagnosed as having a malignant breast cancer. 
      
```{r}
#frequency train data based on the diagnosis
table(train$diagnosis)

#frequency test data based on the diagnosis
table(test$diagnosis)
```


\item[(d)]	Fit a regression model to predict whether tissue samples are malignant or benign. 
Classify cases in the validation set. Compute and discuss the resulting confusion matrix. 

\textcolor{red}{Solution:} We chose to use all of the predictor variables (except for id which has no impact on the diagnosis) for the first regression model. Then, we will identify the most significantvariables. Also, we decided to use a logistic regression function for this model because we are predicting a binary outcome of whether a breast cancer patient has either a benign tumor or a malignant tumor. Moreover, we decided to use the data sets corresponding to the mean and standard error and ignore the "worst" data set. We don't expect the "worst" data to provide any significant value in evaluating whether a patient is either begnin or malignant. 
```{r}
# Fit a logistic regression model for breast cancer diagnosis
set.seed(359)
wbc.glm = glm(diagnosis~radius_mean+texture_mean+perimeter_mean+area_mean+smoothness_mean+
               compactness_mean+concavity_mean+concave_mean+symmetry_mean+fractal_mean+
               radius_standardError+texture_standardError+perimeter_standardError+
               area_standardError+smoothness_standardError+compactness_standardError+
               concavity_standardError+concave_standardError+
               symmetry_standardError+fractal_standardError
               ,data = train
              ,family = binomial
              )

summary(wbc.glm) # Model summary
```

We found that texture_mean,concativity_mean,area_standardError, and concavity_standardError were the only predictors that were significant at 0.05.  

Next, let's consider the performance of this model. 
```{r}
# Get predicted probabilities  
yhat = predict(wbc.glm, newdata = test, type = "response")
```

Next, we will Use a threshold of 0.5 to classify predictions. 
```{r}
# Construct confusion matrix 
table(test$diagnosis, yhat>.5)
```

The confusion matrix tells us that the classifier is accurate at 95.37% or (108+57)/173. Also, we noticed that the model makes 4 false positives related to begnin diagnosis. In other words, these false positive are cases where we predcited patients would be diagnosed as having a benign breast cancer, but instead they had a malignant breast cancer. These false positive rate is at 3.6% or 4/112. Although the wrong diagnosis could be a life changer, we can however say that at 3.6% false positive rate, this is a very good prediction model. 

References: 
\bitem
 \item http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/
\eitem


Next, we will plot the ROC curve for this model 
```{r}
# Plot the ROC curve
roc(test$diagnosis, yhat)

plot(roc(test$diagnosis, yhat), main="Figure 1")

```

We decided to use ROC because it's the most commonly used way to visualize the performance of a binary classifier. Also, we noticed that the AUC or Area under the curve is at 0.99. Ideally, the closer the AUC value is to 1, then the true positive rate will increase quickly. In this case, we will get a model with a higher number of patients being diagnosed accordingly on the type of breast cancer tumor they may have had. Thus, because we have an AUC that's closed to 1 than we can conclude that the classifier is very good. 

When analyzing the ROC curve, we noticed that the curve is above the diagonal line. Also, the ROC shows a pretty good curve that's continualy increasing. In fact, it shows that the curve is getting closer to the upper left hand corner. This is a sign of a close fit of the model. 

References: 
\bitem
 \item https://www.kaggle.com/wiki/AreaUnderCurve
 \item http://blog.yhat.com/posts/roc-curves.html
\eitem

\item[(e)]	Fit a random forest model to predict whether tissue samples are malignant or benign. 
Classify cases in the validation set. Compute and discuss the resulting confusion matrix. 

\textcolor{red}{Solution:} Below we fit the random forest model. We explore the models based on the visualization. 
```{r}
#Factors needed for RandomForest classifier
train$diagnosis = factor(train$diagnosis)

# Fit the RandomForest model
wbc.rf = randomForest(diagnosis~radius_mean+texture_mean+perimeter_mean+area_mean+smoothness_mean+
                        compactness_mean+concavity_mean+concave_mean+symmetry_mean+fractal_mean+
                        radius_standardError+texture_standardError+perimeter_standardError+
                        area_standardError+smoothness_standardError+compactness_standardError+           
                        concavity_standardError+concave_standardError+symmetry_standardError+
                        fractal_standardError
                      ,data = train
                      ,na.action=na.exclude)

# Explore the model
plot(wbc.rf, main="Figure 2")
importance(wbc.rf)
```

\textcolor{red}{Solution:} 500 decision trees or a forest has been built using the Random Forest algorithm based learning. The plot seems to indicate that around 350 decision trees, there is not a significant reduction in error rate. Also the mean importance showed that variables: Concave_mean, area_mean, concativity_mean, perimeter_mean, radius_mean, and area_standardError have the highest MeanDecreaseGini score. Thus, these variables have the highest importance for this model. 


```{r}
# Save prediction from random forest model
yhat2 = predict(wbc.rf, newdata = test, type="prob")[,1]
```

Next, we will plot the ROC curve for this model 
```{r}
# Plot the ROC curve
roc(test$diagnosis, yhat2)

plot(roc(test$diagnosis, yhat2), main="Figure 3")

```

When analyzing the ROC curve, we noticed that the curve is above the diagonal line. Also, the ROC shows a pretty good curve that's continualy increasing. In fact, it shows that the curve is getting closer to the upper left hand corner. This is a sign of a close fit of the model. Also, it shows an AUC = 0.988. This AUC is very good as an AUC = 1 is considered to be a good fit. 

References:
    \bitem
       \item http://www.listendata.com/2014/11/random-forest-with-r.html
   \eitem
     

\item[(f)]	Compare the models from part (d) and (e) using ROC curves. Which do you prefer? Be 
sure to justify your preference. 
```{r}
plot(roc(test$diagnosis, yhat), col='red', main="Figure 4")
lines(roc(test$diagnosis, yhat2), col='green')

```

\textcolor{red}{Solution:}
The above code compares the ROC curves for both the regression model (red line) and the randomforest model (green line). We can see that both models are very close to each other. There is a slight improvement of the logistic regression model over the random forest model. Also, when comparing the AUC(Area Under the Curve) for both models, we noticed that the linear regression model fair a little better with a AUC = 0.994 (see figure 1) while the random forest model has a AUC = 0.988 (see figure 3).

\eitem

##### Problem 4: #####

 
Please answer the questions below by writing a short response.

\bitem
\item[(a)]	Describe three real-life applications in which classiffication might be useful. Describe the 
response, as well as the predictors. Is the goal in each application inference or 
predictions? Explain your answer. 
 
 \textcolor{red}{Solution:} 
  \begin{itemize}
 \item  Real-life application 1 - Should a college footbal team be admitted in the football playoff? Response: Admit/No Admit. Predictors: strength of schedule, championships won, head-to-head competition, Comparative outcomes of common opponents, number of win games. The goal will be a Prediction. Example: University of Washgington college football team. 
   
 \item  Real-life application 2 - Is this new mobile game will be successfull or not? Response: Success/Failure. Predictors: money spent for development, money made from selling ads, easy to learn and play, ease of game progression, goal-oriented gameplay, exciting story-line/plot, target audience. The goal will be a prediction.  Example: Angry Birds. 
   
 \item  Real-life application 3 - Should I buy a new stock for my investment? Response: Buy/Not buy. Predictors: 52 week range, volume (number of stocks bought and sold in a single day), price earnings ratio, earnings per share, market cap, stock volatility, dividends, open interests in option chains, insider activity, news/popularity. The goal will be a prediction. Example: EXP (Expedia)
   \end{itemize}
   
   
References: 
\bitem
 \item https://toughnickel.com/personal-finance/10-Factors-to-Consider-When-Selecting-a-Stock
 \item http://www.gamasutra.com/blogs/IgorMatrofailo/20160107/263164/5_Criteria_of_a_Successful_Mobile_Game.php

   \eitem
   
\item[(b)]	Describe three real-life applications in which regression might be useful. Describe the 
response, as well as the predictors. Is the goal in each application inference or 
predictions? Explain your answer. 
 
 \textcolor{red}{Solution:}
 
 \begin{itemize}
 
\item Real-life regression 1 - What is the average salary that new computer engineers should expect over the next five years? Response: graduate  computer engineer salary for the first year, second year, etc. Predictors: education level, jobs demand, gender, years of experience, speciality, school attended, cities or states where job is located, professional certifications, total internships completed. The goal will be an inference. Example: Google. 
 
\item Real-life regression 2 - Gas milleage that a new jet liner design will result in. Response: variations on the fuel economy by an airline. Predictors: aircraft makers, how fast it flies, how far it flies, number of passengers on the airplane, size of cargo packs, wide or narrow body-jet, structure of the plane, size of fuel on the plane. The goal will be an inference. Example: Alaska Airlines.
 
 \item Real-life regression 3 - High-school graduation increase for minority students. Response: what is the graduation rate predicted to be by 2030 for minority students? Predictors: academic preparation, teacher's skills, math and science rating, readability score, peer-mentoring availability, summer remedial courses availability, minority teachers availability, family and community involvement. The goal will be an inference. Example: 
Minnesota high school. 

\end{itemize}
 

 References: 
  \bitem
      \item http://www.wsj.com/articles/SB10001424052748704901104575423261677748380
       \item http://www.startribune.com/minnesota-graduation-rates-flat-but-more-minority-students-finishing-school/369661641/
      
   \eitem
   
\item[(c)]	What are the advantages and disadvantages of a very flexible (versus a less flexible) approach 
for regression or classiffication? Under what circumstances might a more flexible approach be 
preferred to a less flexible approach? When might a less flexible approach be preferred? 

 \textcolor{red}{Solution:}
 
  The advantages of a very flexible approach for regression or classification are:
  \begin{itemize}
    \item Tends to reduce bias 
    \item Less likely to overfit when using a larget data set
    \item In most cases, it will perform better than a less flexible approach
    \item Help in fiding a non-linear option 
   \end{itemize}
    
  The disavantages of a very flexible approach are:
   \begin{itemize}
      \item More prone to overfitting
   \end{itemize}
    
  More flexible approach is preffered over a less flexible when: 
   \begin{itemize}
    \item The sample size is large and the number of predictors is small.
    \item The relationship between the predictors and the sample size is small
    \item Use for prediction model
   \end{itemize}
    
  Less flexible approach is preffered  over a more flexible when: 
   \begin{itemize}
   \item The number of predictors is large and the sample size is small
   \item The variance of the errors is large
   \item Use for inference model 
   \end{itemize}
   
\eitem

##### Problem 5 #####

Suppose we have a dataset with ve predictors, X1 = GPA, X2 = IQ, X3 = Gender (1 for Female, and 
0 for Male), X4 = Interaction between GPA and IQ, and X5 = Interaction between GPA and Gender. 
The response is starting salary after graduation (in thousands of dollars). Suppose we use 
least squares to fit the model and get$, \beta_0$=50,$\beta_1$=20,$\beta_2$=0.07,$\beta_3$=35,$\beta_4$=0.01, and  $\beta_5$=-10.

\bitem
\item[(a)]	Which answer is correct and why? 

  \bitem
   \item[i.]	For a  fixed value of IQ and GPA, males earn more on average than females. 
  
   \item[ii.]	For a  fixed value of IQ and GPA, females earn more on average than males. 
  
   \item[iii.]	For a fixed value of IQ and GPA, males earn more on average than females provided that the GPA is high enough. 

   \item[iv.]	For a fixed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough. 
  \eitem  

\textcolor{red}{Solution:}

Salary = 50 + 20X1 + 0.07X2 + 35X3 + 0.01X4-10X5

X4 = X1*X2 because it represents the interaction between GPA and IQ. 
X5 = X1*X3 because it represents the interaction between GPA and Gender. 
Since, the question is about gender, then we will consider terms that contain gender and everything else will be part of the constant value. Thus, our equation will change to:

Salary = 35X3 - 10X5 + constant 

replacing X5 by it's correspond values, we got Salary = 35X3 - 10(X1*X3) + constant

*Case 1: calculating a female's salary 
    knowing that a female's gender = 1 then replacing X3 by 1 thus we have salary = 35 -10(1*GPA)  + constant
    Salary = 35 - 10GPA + constant

*Case 2: calculating a male's salary
    knowing that a male's gender = 0 then replacing X3 by 0 thus we have salary = 35*0 -10(0*GPA)  + constant
    Salary = constant
    
Assuming both gender's make the salary then we can solve for GPA.
  35-10GPA+constant = constant
  35 -10GPA = 0
  -10GPA = -35 or 10GPA = 35 or GPA = 35/10 or 3.5

We can conclude the followings:

* scenario 1. if men have a GPA greater than 3.5 then women will make less. 35-10*4 will result to a negative value and adding to a constant will always be less than men's constant value. 

* scenario 2. If men have a GPA less than 3.5 then women will make more than men. 35-10*2.0 will result to a positive value added to the constant value which wil be greater than men's constant value. 
  
* scenario 3. If men have a GPA = 3.5 then both women and men will make the same salary. 35-10.3.5 = 0 will result to both men and women having the same constant salary. 
  
**Based on the scenearios listed, then option 3 is the correct answer.** 
 
  
\item[(b)]	Predict the salary of a female with IQ of 110 and a GPA of 4.0. 

\textcolor{red}{Solution:}

Salary = 50 + 20X1 + 0.07X2 + 35X3 + 0.01(X1*X2)-10(X1*X3)
salary = 50 + 20*4.0 + 0.07*110 + 35*1 + 0.01(4.0*110) - 10(4.0*1)
salary = 50+80.0+7.7+35+4.4-40 = 137.1

**A female's with IQ = 110 and a GPA = 4.0 will have a salary = $137,100 per year.**

       
\item[(c)]	True or false: Since the coefficient for the GPA/IQ interaction term is very small, there is little evidence of an interaction effect. Justify your answer. 

\textcolor{red}{Solution:}
    **False.** We will need to calculate the null hypothesis probability of wheher there is little evidence of an interaction effect. if the null hypothesis is less than the selected type 1 error threshold then we reject the null hypothesis. 

\eitem

##### Problem 6 - Extra Credit#####
Apply boosting, bagging and random forests to a dataset of your choice that we have used in class. 
Be sure to fit the models on a training set and evaluate their performance on a test set.

 \bitem
  \item[(a)]	How accurate are the results compared to simple methods like linear or logistic regression? 
  
  \item[(b)]	Which of the approaches yields the best performance? 
  \eitem

##### Problem 7 - Extra Credit#####
Suppose that X1; : : : Xn form a random sample from a Poisson distribution for which the mean pierre
is unknown, ( > 0).

 \bitem

 \item[(a)]	Determine the MLE of pierre, assuming that at least one of the observed values is different from 
    0. Show your work. 

  \item[(b)]	Show that the MLE of  does not exists if every observed value is 0. 
  \eitem


##### Statement of Compliance ####

I affirm that I have had no conversation regarding this exam with any persons other than the 
instructor (Dr. Emma Spiro). Further, I certify that the attached work represents my own thinking. 
Any information, concepts, or words that originate from other sources are cited in accordance with 
University of Washington guidelines as published in the Academic Code (available on the course 
website). I am aware of the serious consequences that result from improper discussions with others 
or from the improper citation of work that is not my own.


(signature) Pierre Augustamar

(date) 12/13/2016


